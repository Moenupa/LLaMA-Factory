[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "llamafactory"
requires-python = ">=3.9.0"
dynamic = [
    "version",
    "scripts",
    "authors",
    "description",
    "readme",
    "license",
    "keywords",
    "classifiers"
]
dependencies = [
    # core deps
    "transformers>=4.49.0,<=4.56.2,!=4.52.0; python_version < '3.10'",
    "transformers>=4.49.0,<=4.57.1,!=4.52.0,!=4.57.0; python_version >= '3.10'",
    "datasets>=2.16.0,<=4.0.0",
    "accelerate>=1.3.0,<=1.11.0",
    "peft>=0.14.0,<=0.17.1",
    "trl>=0.8.6,<=0.9.6",
    # gui
    "gradio>=4.38.0,<=5.45.0",
    "matplotlib>=3.7.0",
    "tyro<0.9.0",
    # ops
    "einops",
    "numpy<2.0.0",
    "pandas>=2.0.0",
    "scipy",
    # model and tokenizer
    "sentencepiece",
    "tiktoken",
    # "modelscope>=1.14.0",
    "hf-transfer",
    "safetensors<=0.5.3",
    # python
    "fire",
    "omegaconf",
    "packaging",
    "protobuf",
    "pyyaml",
    "pydantic<=2.10.6",
    # api
    "uvicorn",
    "fastapi",
    "sse-starlette",
    # media
    "av<16.0.0",
    "librosa",
    # fixes
    "propcache!=0.4.0",
]

[project.optional-dependencies]
torch = [
    "torch>=2.7.1",
    "torchvision>=0.22.1",
]
flash_attn = [
    "flash-attn==2.8.2",
    "flashinfer-python",
]
deepspeed = [
    "deepspeed>=0.10.0,<=0.16.9",
    "deepspeed-kernels",
]
bitsandbytes=["bitsandbytes>=0.39.0"]
metrics = [
    "nltk",
    "jieba",
    "rouge-chinese",
]
vllm = ["vllm>=0.4.3,<=0.11.0"]
galore = ["galore-torch"]
apollo = ["apollo-torch"]
badam = ["badam>=1.2.1"]
wandb = ["wandb"]

[dependency-groups]
dev = [
    "pre-commit",
    "ruff",
    "pytest",
    "build"
]

[tool.ruff]
target-version = "py39"
line-length = 119
indent-width = 4

[tool.ruff.lint]
ignore = [
    "C408", # collection
    "C901", # complex
    "E501", # line too long
    "E731", # lambda function
    "E741", # ambiguous var name
    "D100", # no doc public module
    "D101", # no doc public class
    "D102", # no doc public method
    "D103", # no doc public function
    "D104", # no doc public package
    "D105", # no doc magic method
    "D107", # no doc __init__
]
extend-select = [
    "C",      # complexity
    "E",      # error
    "F",      # pyflakes
    "I",      # isort
    "W",      # warning
    "UP",     # pyupgrade
    "D",      # pydocstyle
    "PT009",  # pytest assert
    "RUF022", # sort __all__
]

[tool.ruff.lint.isort]
lines-after-imports = 2
known-first-party = ["llamafactory"]
known-third-party = [
    "accelerate",
    "datasets",
    "gradio",
    "numpy",
    "peft",
    "torch",
    "transformers",
    "trl",
]

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
docstring-code-format = true
skip-magic-trailing-comma = false
line-ending = "auto"

[tool.uv]
no-build-isolation-package = ["flash-attn"]
conflicts = []

[tool.uv.sources]
torch = [
  { index = "pytorch-cu128", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
torchvision = [
  { index = "pytorch-cu128", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]

[[tool.uv.index]]
name = "pytorch-cu121"
url = "https://download.pytorch.org/whl/cu121"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu126"
url = "https://download.pytorch.org/whl/cu126"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true
